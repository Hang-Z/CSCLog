{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628c9529-4fe6-448c-bf37-8116ed4ec540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022-11-23\n",
    "# add sentences emb and time emb\n",
    "# add full model\n",
    "# add params of val module for candidate and rate, multi-classification task\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import nni\n",
    "import json\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import dateutil.parser\n",
    "\n",
    "from utils import pytorchtools\n",
    "from collections import Counter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_recall_fscore_support, top_k_accuracy_score\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    seed = int(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = True\n",
    "\n",
    "seed_torch(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff3804c5-0c2f-4d37-bfc4-a99803d4e7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPLayer(nn.Module):\n",
    "    def __init__(self, dmodel, hid_size, drop, training):\n",
    "        super(MLPLayer, self).__init__()\n",
    "        self.dmodel = dmodel\n",
    "        self.hid_size = hid_size\n",
    "        self.drop = drop\n",
    "        \n",
    "        self.fc0 = nn.Linear(dmodel, hid_size)\n",
    "        self.fc1 = nn.Linear(hid_size, hid_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = f.relu(self.fc0(x))\n",
    "        x = f.dropout(x, p=self.drop, training=self.training)\n",
    "        x = f.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class CNNLayer(nn.Module):\n",
    "    def __init__(self, dmodel, hid_size, ksize, drop, training):\n",
    "        super(CNNLayer, self).__init__()\n",
    "        self.dmodel = dmodel\n",
    "        self.hid_size = hid_size\n",
    "        self.ksize = ksize\n",
    "        self.drop = drop\n",
    "        \n",
    "        self.cnn0 = nn.Conv1d(dmodel, hid_size, kernel_size=ksize, stride=1, padding=0)\n",
    "        self.cnn1 = nn.Conv1d(hid_size, hid_size, kernel_size=ksize, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = f.relu(self.cnn0(x))\n",
    "        x = f.dropout(x, p=self.drop, training=self.training)\n",
    "        x = f.relu(self.cnn1(x))\n",
    "        return x\n",
    "    \n",
    "class FTEncoder(nn.Module):\n",
    "    def __init__(self, sen_size, hidden_size, alpha=0.5, pattern=0):\n",
    "        super(FTEncoder, self).__init__()\n",
    "        self.pattern = pattern\n",
    "        assert self.pattern in [0, 1, 2], \"pattern just in cat_first 0 or nn_first 1 or add_first 2\"\n",
    "        if pattern == 1:\n",
    "            self.alpha = alpha\n",
    "            assert alpha < 1 and alpha > 0, \"alpha is rate just in (0,1)\"\n",
    "            sen_fc_size = int(hidden_size * alpha)\n",
    "            time_fc_size = hidden_size - sen_fc_size\n",
    "            print('x:{}, sen_x:{}, time_x:{}'.format(hidden_size, sen_fc_size, time_fc_size))\n",
    "            self.sen_fc = nn.Linear(sen_size, sen_fc_size)\n",
    "            self.time_fc = nn.Linear(1, time_fc_size)\n",
    "        elif pattern == 0:\n",
    "            self.cat_fc = nn.Linear(sen_size + 1, hidden_size)\n",
    "        elif pattern == 2:\n",
    "            self.sen_fc = nn.Linear(sen_size, hidden_size)\n",
    "            self.time_fc = nn.Linear(1, hidden_size)\n",
    "    \n",
    "    def forward(self, x): # x(sen_x, time_x)\n",
    "        if self.pattern == 0:\n",
    "            cat_x = torch.cat((x[0], x[1].unsqueeze(-1)), -1)\n",
    "            cat_x = self.cat_fc(cat_x)\n",
    "        elif self.pattern == 1:\n",
    "            sen_x = self.sen_fc(x[0])\n",
    "            time_x = self.time_fc(x[1].unsqueeze(-1))\n",
    "            cat_x = torch.cat((sen_x, time_x), -1)\n",
    "        elif self.pattern == 2:\n",
    "            cat_x = self.sen_fc(x[0]) + self.time_fc(x[1].unsqueeze(-1))\n",
    "        return cat_x\n",
    "    \n",
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # out = self.fc(out[:, -1, :])\n",
    "        return out[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a871eb2-067d-4002-9f24-ecf7104fcd83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IREncoder(nn.Module):\n",
    "    def __init__(self, dmodel, mlp_hid_size, gcn_hid_size, drop, com_num, training):\n",
    "        super(IREncoder, self).__init__()\n",
    "        self.dmodel = dmodel\n",
    "        self.mlp_hid_size = mlp_hid_size\n",
    "        self.gcn_hid_size = gcn_hid_size\n",
    "        # self.ksize = ksize\n",
    "        self.drop = drop\n",
    "        self.com_num = com_num\n",
    "        self.taining = training\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.edge_mlp = MLPLayer(2*dmodel, mlp_hid_size, drop, training)\n",
    "        self.mlp_out = nn.Linear(mlp_hid_size, 1)\n",
    "        \n",
    "        # self.edge_cnn = CNNLayer(hid_size, hid_size, ksize, drop, training)\n",
    "        self.cnn_out = nn.Conv1d(mlp_hid_size, 1, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.GCN0 = GCNConv(dmodel, gcn_hid_size)\n",
    "        self.GCN1 = GCNConv(gcn_hid_size, dmodel)\n",
    "        \n",
    "    def rel_pyg(self, node):\n",
    "        rec2edge_index = []\n",
    "        send2edge_index = []\n",
    "        for i in range(len(node)):\n",
    "            for j in range(i + 1 , len(node)):\n",
    "                rec2edge_index.append(node[i])\n",
    "                send2edge_index.append(node[j])\n",
    "        rec2edge_index = torch.as_tensor(rec2edge_index, dtype=torch.long).to(self.device)\n",
    "        send2edge_index = torch.as_tensor(send2edge_index, dtype=torch.long).to(self.device)\n",
    "        return torch.stack([rec2edge_index, send2edge_index])\n",
    "    \n",
    "    def gumbel_softmax(self, x, axis=1):\n",
    "        trans_input = x.transpose(axis, 0).contiguous()\n",
    "        soft_max_1d = f.softmax(trans_input)\n",
    "        return soft_max_1d.transpose(axis, 0)\n",
    "    \n",
    "    def node2edge(self, x, index):\n",
    "        edge_index = self.rel_pyg(index)\n",
    "        edge_x = torch.cat([x[edge_index[0]], x[edge_index[1]]], -1)\n",
    "        return edge_x, edge_index\n",
    "    \n",
    "    def forward(self, x, index):\n",
    "        padding_x = torch.zeros([self.com_num, self.dmodel], requires_grad=True).to(self.device)\n",
    "        padding_x[index] = x\n",
    "        edge_x, edge_index = self.node2edge(padding_x, index)\n",
    "        \n",
    "        # (c):MLP+CNN\n",
    "        edge_x = self.edge_mlp(edge_x)\n",
    "        # edge_x = edge_x.unsqueeze(0).permute(0, 2, 1)\n",
    "        # edge_x = self.cnn_out(edge_x)\n",
    "        # edge_x = edge_x.permute(0, 2, 1).squeeze(0)\n",
    "        edge_x = self.mlp_out(edge_x)\n",
    "        \n",
    "        edge_weight = self.gumbel_softmax(edge_x)\n",
    "        \n",
    "        out =f.relu(self.GCN0(padding_x, edge_index, edge_weight))\n",
    "        out =f.dropout(out, self.drop, training=self.training)\n",
    "        out = self.GCN1(out, edge_index, edge_weight)\n",
    "        \n",
    "        return out[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b1ad8d0-4353-49d4-92d8-1617e8bae58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, com_num, hidden_size, alpha, pattern, \\\n",
    "                 num_layers, num_keys, drop = 0.1, training = True):\n",
    "        super(Model, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        ft_hid_size, lstm_hid_size, mlp_hid_size, gcn_hid_size, out_hid_size = hidden_size # unzip\n",
    "        self.lstm_hid_size = lstm_hid_size\n",
    "        self.com_num = com_num\n",
    "        # (a)\n",
    "        self.ftencoder = FTEncoder(input_size, ft_hid_size, alpha, pattern)\n",
    "        # (b)\n",
    "        self.lstm0 = LSTMEncoder(ft_hid_size, lstm_hid_size, num_layers)\n",
    "        # self.lstm1 = LSTMEncoder(input_size, hidden_size, num_layers)\n",
    "        self.lstm2 = LSTMEncoder(ft_hid_size, lstm_hid_size, num_layers)\n",
    "        # (c)\n",
    "        self.irencoder = IREncoder(lstm_hid_size, mlp_hid_size, gcn_hid_size, drop, com_num, training)\n",
    "        # (d)\n",
    "        self.att_fc = nn.Linear(lstm_hid_size, lstm_hid_size)\n",
    "        self.fc1 = nn.Linear(2*lstm_hid_size, out_hid_size)\n",
    "        self.fc2 = nn.Linear(out_hid_size, num_keys)\n",
    "        \n",
    "        # variable\n",
    "        self.u_att = Variable(torch.zeros(1, lstm_hid_size), requires_grad=True).to(self.device)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.u_att, gain=nn.init.calculate_gain('relu'))\n",
    "        print('Variabel inited.')\n",
    "        \n",
    "    def resolve(self, per_x, per_index):\n",
    "        res = collections.OrderedDict()\n",
    "        for idx in range(per_x.shape[0]):\n",
    "            if per_index[idx].item() not in res.keys():\n",
    "                res[per_index[idx].item()] = []\n",
    "            res[per_index[idx].item()].append(per_x[idx].to(self.device))\n",
    "        return res\n",
    "    \n",
    "    def attention_net(self, x): # [16, 8, 512] [1, 512]\n",
    "        sequence_len = x.shape[1]\n",
    "        re_x = x.reshape(-1, self.lstm_hid_size)\n",
    "        re_x = torch.mm(re_x, self.u_att.T).reshape(-1, sequence_len)\n",
    "        re_x = f.softmax(re_x, dim=1).unsqueeze(-1)\n",
    "        \n",
    "        x = torch.sum(x * re_x, 1)\n",
    "        x = f.relu(self.att_fc(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, index, q_x, t_x):\n",
    "        # (a): feature extra\n",
    "        x = self.ftencoder((x, t_x))\n",
    "        # (b): lstm layer\n",
    "        batch_as_x = self.lstm0(x)\n",
    "        # out1 = self.lstm1(q_x.unsqueeze(1))\n",
    "        \n",
    "        batch_ac_x = []\n",
    "        for idx in range(x.shape[0]):\n",
    "            res = self.resolve(x[idx], index[idx])\n",
    "            ac_x = []\n",
    "            for item in res.items():\n",
    "                list_x = torch.stack(item[1]).unsqueeze(0)\n",
    "                out_x = self.lstm2(list_x)\n",
    "                ac_x.append(out_x.squeeze(0))\n",
    "            ac_x = torch.stack(ac_x)\n",
    "            \n",
    "            # (c):\n",
    "            if ac_x.shape[0] != 1:\n",
    "                ac_x = self.irencoder(ac_x, list(res.keys()))\n",
    "            \n",
    "            # (d): attention pooling\n",
    "            ac_x = self.attention_net(ac_x.unsqueeze(0)) # add batch\n",
    "            batch_ac_x.append(ac_x)\n",
    "        \n",
    "        batch_ac_x = torch.stack(batch_ac_x).squeeze(1)\n",
    "        multi_out = torch.cat((batch_as_x, batch_ac_x), -1)\n",
    "        out = f.relu(self.fc1(multi_out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa1bed8a-2aac-4b6d-9d59-8e0aa21097da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_wo_ic(nn.Module):\n",
    "    def __init__(self, input_size, com_num, hidden_size, alpha, pattern, \\\n",
    "                 num_layers, num_keys, drop = 0.1, training = True):\n",
    "        super(Model_wo_ic, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        ft_hid_size, lstm_hid_size, mlp_hid_size, gcn_hid_size, out_hid_size = hidden_size # unzip\n",
    "        self.lstm_hid_size = lstm_hid_size\n",
    "        self.com_num = com_num\n",
    "        # (a)\n",
    "        self.ftencoder = FTEncoder(input_size, ft_hid_size, alpha, pattern)\n",
    "        # (b)\n",
    "        self.lstm0 = LSTMEncoder(ft_hid_size, lstm_hid_size, num_layers)\n",
    "        # self.lstm1 = LSTMEncoder(input_size, hidden_size, num_layers)\n",
    "        self.lstm2 = LSTMEncoder(ft_hid_size, lstm_hid_size, num_layers)\n",
    "        # (c)\n",
    "        self.irencoder = IREncoder(lstm_hid_size, mlp_hid_size, gcn_hid_size, drop, com_num, training)\n",
    "        # (d)\n",
    "        self.att_fc = nn.Linear(lstm_hid_size, lstm_hid_size)\n",
    "        self.fc1 = nn.Linear(2*lstm_hid_size, out_hid_size)\n",
    "        self.fc2 = nn.Linear(out_hid_size, num_keys)\n",
    "        \n",
    "        # variable\n",
    "        self.u_att = Variable(torch.zeros(1, lstm_hid_size), requires_grad=True).to(self.device)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.u_att, gain=nn.init.calculate_gain('relu'))\n",
    "        print('Variabel inited.')\n",
    "        \n",
    "    def resolve(self, per_x, per_index):\n",
    "        res = collections.OrderedDict()\n",
    "        for idx in range(per_x.shape[0]):\n",
    "            if per_index[idx].item() not in res.keys():\n",
    "                res[per_index[idx].item()] = []\n",
    "            res[per_index[idx].item()].append(per_x[idx].to(self.device))\n",
    "        return res\n",
    "    \n",
    "    def attention_net(self, x): # [16, 8, 512] [1, 512]\n",
    "        sequence_len = x.shape[1]\n",
    "        re_x = x.reshape(-1, self.lstm_hid_size)\n",
    "        re_x = torch.mm(re_x, self.u_att.T).reshape(-1, sequence_len)\n",
    "        re_x = f.softmax(re_x, dim=1).unsqueeze(-1)\n",
    "        \n",
    "        x = torch.sum(x * re_x, 1)\n",
    "        x = f.relu(self.att_fc(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, index, q_x, t_x):\n",
    "        # (a): feature extra\n",
    "        x = self.ftencoder((x, t_x))\n",
    "        # (b): lstm layer\n",
    "        batch_as_x = self.lstm0(x)\n",
    "        # out1 = self.lstm1(q_x.unsqueeze(1))\n",
    "        \n",
    "        batch_ac_x = []\n",
    "        for idx in range(x.shape[0]):\n",
    "            res = self.resolve(x[idx], index[idx])\n",
    "            ac_x = []\n",
    "            for item in res.items():\n",
    "                list_x = torch.stack(item[1]).unsqueeze(0)\n",
    "                out_x = self.lstm2(list_x)\n",
    "                ac_x.append(out_x.squeeze(0))\n",
    "            ac_x = torch.stack(ac_x)\n",
    "            \n",
    "#             # (c):\n",
    "#             if ac_x.shape[0] != 1:\n",
    "#                 ac_x = self.irencoder(ac_x, list(res.keys()))\n",
    "            \n",
    "            # (d): attention pooling\n",
    "            ac_x = self.attention_net(ac_x.unsqueeze(0)) # add batch\n",
    "            batch_ac_x.append(ac_x)\n",
    "        \n",
    "        batch_ac_x = torch.stack(batch_ac_x).squeeze(1)\n",
    "        multi_out = torch.cat((batch_as_x, batch_ac_x), -1)\n",
    "        out = f.relu(self.fc1(multi_out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fab942e-c9b1-4583-a210-756f96b150b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model_noS(nn.Module):\n",
    "    def __init__(self, input_size, com_num, hidden_size, alpha, pattern, \\\n",
    "                 num_layers, num_keys, drop = 0.1, training = True):\n",
    "        super(Model_noS, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        ft_hid_size, lstm_hid_size, mlp_hid_size, gcn_hid_size, out_hid_size = hidden_size # unzip\n",
    "        self.lstm_hid_size = lstm_hid_size\n",
    "        self.com_num = com_num\n",
    "        # (a)\n",
    "        self.ftencoder = FTEncoder(input_size, ft_hid_size, alpha, pattern)\n",
    "        # (b)\n",
    "        self.lstm0 = LSTMEncoder(ft_hid_size, lstm_hid_size, num_layers)\n",
    "        # self.lstm1 = LSTMEncoder(input_size, hidden_size, num_layers)\n",
    "        self.lstm2 = dict()\n",
    "        for cn in range(com_num):\n",
    "            self.lstm2[cn] = LSTMEncoder(ft_hid_size, lstm_hid_size, num_layers).to(device)\n",
    "        # (c)\n",
    "        self.irencoder = IREncoder(lstm_hid_size, mlp_hid_size, gcn_hid_size, drop, com_num, training)\n",
    "        # (d)\n",
    "        self.att_fc = nn.Linear(lstm_hid_size, lstm_hid_size)\n",
    "        self.fc1 = nn.Linear(2*lstm_hid_size, out_hid_size)\n",
    "        self.fc2 = nn.Linear(out_hid_size, num_keys)\n",
    "        \n",
    "        # variable\n",
    "        self.u_att = Variable(torch.zeros(1, lstm_hid_size), requires_grad=True).to(self.device)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.u_att, gain=nn.init.calculate_gain('relu'))\n",
    "        print('Variabel inited.')\n",
    "        \n",
    "    def resolve(self, per_x, per_index):\n",
    "        res = collections.OrderedDict()\n",
    "        for idx in range(per_x.shape[0]):\n",
    "            if per_index[idx].item() not in res.keys():\n",
    "                res[per_index[idx].item()] = []\n",
    "            res[per_index[idx].item()].append(per_x[idx])\n",
    "        return res\n",
    "    \n",
    "    def attention_net(self, x): # [16, 8, 512] [1, 512]\n",
    "        sequence_len = x.shape[1]\n",
    "        re_x = x.reshape(-1, self.lstm_hid_size)\n",
    "        re_x = torch.mm(re_x, self.u_att.T).reshape(-1, sequence_len)\n",
    "        re_x = f.softmax(re_x, dim=1).unsqueeze(-1)\n",
    "        \n",
    "        x = torch.sum(x * re_x, 1)\n",
    "        x = f.relu(self.att_fc(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, index, q_x, t_x):\n",
    "        # (a): feature extra\n",
    "        x = self.ftencoder((x, t_x))\n",
    "        # (b): lstm layer\n",
    "        batch_as_x = self.lstm0(x)\n",
    "        # out1 = self.lstm1(q_x.unsqueeze(1))\n",
    "        \n",
    "        batch_ac_x = []\n",
    "        for idx in range(x.shape[0]):\n",
    "            res = self.resolve(x[idx], index[idx])\n",
    "            ac_x = []\n",
    "            for item in res.items():\n",
    "                list_x = torch.stack(item[1]).unsqueeze(0).to(self.device)\n",
    "                out_x = self.lstm2[item[0]](list_x)\n",
    "                ac_x.append(out_x.squeeze(0))\n",
    "            ac_x = torch.stack(ac_x)\n",
    "            \n",
    "            # (c):\n",
    "            if ac_x.shape[0] != 1:\n",
    "                ac_x = self.irencoder(ac_x, list(res.keys()))\n",
    "            \n",
    "            # (d): attention pooling\n",
    "            ac_x = self.attention_net(ac_x.unsqueeze(0)) # add batch\n",
    "            batch_ac_x.append(ac_x)\n",
    "        \n",
    "        batch_ac_x = torch.stack(batch_ac_x).squeeze(1)\n",
    "        multi_out = torch.cat((batch_as_x, batch_ac_x), -1)\n",
    "        out = f.relu(self.fc1(multi_out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb1579d6-7f17-4a79-b1a9-c698a72bc7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_wo_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, com_num, hidden_size, alpha, pattern, \\\n",
    "                 num_layers, num_keys, drop = 0.1, training = True):\n",
    "        super(Model_wo_LSTM, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        ft_hid_size, lstm_hid_size, mlp_hid_size, gcn_hid_size, out_hid_size = hidden_size # unzip\n",
    "        self.lstm_hid_size = lstm_hid_size\n",
    "        self.com_num = com_num\n",
    "        # (a)\n",
    "        self.ftencoder = FTEncoder(input_size, ft_hid_size, alpha, pattern)\n",
    "        # (b)\n",
    "        # self.lstm0 = LSTMEncoder(ft_hid_size, lstm_hid_size, num_layers)\n",
    "        # # self.lstm1 = LSTMEncoder(input_size, hidden_size, num_layers)\n",
    "        # self.lstm2 = LSTMEncoder(ft_hid_size, lstm_hid_size, num_layers)\n",
    "        self.lstm2nn = nn.Linear(ft_hid_size, lstm_hid_size)\n",
    "        # (c)\n",
    "        self.irencoder = IREncoder(lstm_hid_size, mlp_hid_size, gcn_hid_size, drop, com_num, training)\n",
    "        # (d)\n",
    "        self.att_fc = nn.Linear(lstm_hid_size, lstm_hid_size)\n",
    "        self.fc1 = nn.Linear(2*lstm_hid_size, out_hid_size)\n",
    "        self.fc2 = nn.Linear(out_hid_size, num_keys)\n",
    "        \n",
    "        # variable\n",
    "        self.u_att = Variable(torch.zeros(1, lstm_hid_size), requires_grad=True).to(self.device)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.u_att, gain=nn.init.calculate_gain('relu'))\n",
    "        print('Variabel inited.')\n",
    "        \n",
    "    def resolve(self, per_x, per_index):\n",
    "        res = collections.OrderedDict()\n",
    "        for idx in range(per_x.shape[0]):\n",
    "            if per_index[idx].item() not in res.keys():\n",
    "                res[per_index[idx].item()] = []\n",
    "            res[per_index[idx].item()].append(per_x[idx].to(self.device))\n",
    "        return res\n",
    "    \n",
    "    def attention_net(self, x): # [16, 8, 512] [1, 512]\n",
    "        sequence_len = x.shape[1]\n",
    "        re_x = x.reshape(-1, self.lstm_hid_size)\n",
    "        re_x = torch.mm(re_x, self.u_att.T).reshape(-1, sequence_len)\n",
    "        re_x = f.softmax(re_x, dim=1).unsqueeze(-1)\n",
    "        \n",
    "        x = torch.sum(x * re_x, 1)\n",
    "        x = f.relu(self.att_fc(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, index, q_x, t_x):\n",
    "        # (a): feature extra\n",
    "        x = self.ftencoder((x, t_x))\n",
    "        # (b): lstm layer\n",
    "        batch_as_x = torch.mean(x, 1)\n",
    "        batch_as_x = self.lstm2nn(batch_as_x)\n",
    "        # out1 = self.lstm1(q_x.unsqueeze(1))\n",
    "        \n",
    "        batch_ac_x = []\n",
    "        for idx in range(x.shape[0]):\n",
    "            res = self.resolve(x[idx], index[idx])\n",
    "            ac_x = []\n",
    "            for item in res.items():\n",
    "                list_x = torch.stack(item[1]).unsqueeze(0)\n",
    "                out_x = torch.mean(list_x, 1)\n",
    "                out_x = self.lstm2nn(out_x)\n",
    "                ac_x.append(out_x.squeeze(0))\n",
    "            ac_x = torch.stack(ac_x)\n",
    "            \n",
    "            # (c):\n",
    "            if ac_x.shape[0] != 1:\n",
    "                ac_x = self.irencoder(ac_x, list(res.keys()))\n",
    "            \n",
    "            # (d): attention pooling\n",
    "            ac_x = self.attention_net(ac_x.unsqueeze(0)) # add batch\n",
    "            batch_ac_x.append(ac_x)\n",
    "        \n",
    "        batch_ac_x = torch.stack(batch_ac_x).squeeze(1)\n",
    "        multi_out = torch.cat((batch_as_x, batch_ac_x), -1)\n",
    "        out = f.relu(self.fc1(multi_out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d540392-e5cb-4845-b27a-f55adfbdecf7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getPath(name, train_name, emb_pattern = 'sen'):\n",
    "    assert emb_pattern in ['one', 'sen'], 'emb_pattern just in one_hot or sentences'\n",
    "    print('Load name: {} and used_name: {}'.format(name, train_name))\n",
    "    \n",
    "    train_path = train_name + '/train_normal.csv'\n",
    "    # val_normal_path = train_name + '/val_normal.csv'\n",
    "    # val_anomaly_path = train_name + '/val_anomaly.csv'\n",
    "    val_normal_path = train_name + '/test_normal.csv'\n",
    "    val_anomaly_path = train_name + '/test_anomaly.csv'\n",
    "    test_normal_path = train_name + '/test_normal.csv'\n",
    "    test_anomaly_path = train_name + '/test_anomaly.csv'\n",
    "    \n",
    "    temp_path = name + '.log_templates.csv'\n",
    "    emb_path = name + '_one_hot.json'\n",
    "    if emb_pattern == 'sen':\n",
    "        emb_path = name + '_sentences_emb.json'\n",
    "    com_path = name + '_component.json'\n",
    "    \n",
    "    return train_path, val_normal_path, val_anomaly_path, temp_path, emb_path, com_path, test_normal_path, test_anomaly_path\n",
    "\n",
    "def getDateTimeFromISO8601String(s):\n",
    "    d = dateutil.parser.parse(s, yearfirst=True)\n",
    "    return d\n",
    "\n",
    "def generate_train(name, train_path, logTemp_path, encoder_path, com_path, window_size):\n",
    "    train_datas = pd.read_csv(train_path, engine='c', na_filter=False, memory_map=True)\n",
    "    logTemp = pd.read_csv(logTemp_path, index_col='EventId', engine='c', na_filter=False, memory_map=True)\n",
    "    mapping = {index: i for i, index in enumerate(logTemp.index.unique())}\n",
    "    emb = json.load(open(encoder_path, 'r'))\n",
    "    cop = json.load(open(com_path, 'r'))\n",
    "    num_keys = len(logTemp.index.unique())\n",
    "    \n",
    "    # slide sample\n",
    "    inputs, outputs = [], []\n",
    "    for idx, row in train_datas.iterrows():\n",
    "        # seqs = row['EventSequence'][1:-1].replace('\\'', '').replace(' ','').split(',')\n",
    "        seqs = eval(row['EventSequence'])\n",
    "        len_seq = len(seqs)\n",
    "        inputs.extend([seqs[i:i + window_size] for i in range(len_seq - window_size)])\n",
    "        outputs.extend([mapping[seqs[i + window_size][0]] for i in range(len_seq - window_size)])\n",
    "    \n",
    "    # encoder\n",
    "    inputs_encoded, coms_encoded, quans_encoded, time_encoded = [], [], [], []\n",
    "    for idx, events in enumerate(inputs):\n",
    "        \n",
    "        # quan encoder\n",
    "        quan_pattern = [0] * num_keys\n",
    "        log_counter = Counter([mapping[event] for event, _, _ in events])\n",
    "        for key in log_counter:\n",
    "            quan_pattern[key] = log_counter[key]\n",
    "        quans_encoded.append(quan_pattern)\n",
    "        \n",
    "        inp, com, tm = [], [], []\n",
    "        start_time = getDateTimeFromISO8601String(events[0][2])\n",
    "        for event, component, time in events:\n",
    "            cur_time = getDateTimeFromISO8601String(time)\n",
    "            inp.append(emb[event])\n",
    "            com.append(cop[component])\n",
    "            tm.append((cur_time - start_time).seconds)\n",
    "            \n",
    "        inputs_encoded.append(inp)\n",
    "        coms_encoded.append(com)\n",
    "        time_encoded.append(tm)\n",
    "    dataset = TensorDataset(torch.as_tensor(inputs_encoded, dtype=torch.float), torch.as_tensor(coms_encoded),\\\n",
    "                            torch.as_tensor(quans_encoded, dtype=torch.float), torch.as_tensor(time_encoded, dtype=torch.float), torch.as_tensor(outputs))\n",
    "    \n",
    "    print('Number of {}_seqs: {}, components: {}'.format(name, len(dataset), len(cop)))\n",
    "    \n",
    "    return dataset, len(inputs_encoded[0][0]), len(logTemp.index.unique()), len(cop)\n",
    "\n",
    "def generate_pre(name, log_path, logTemp_path, encoder_path, com_path, window_size):\n",
    "    pre_data = pd.read_csv(log_path, engine='c', na_filter=False, memory_map=True)\n",
    "    logTemp = pd.read_csv(logTemp_path, index_col='EventId', engine='c', na_filter=False, memory_map=True)\n",
    "    mapping = {index: i for i, index in enumerate(logTemp.index.unique())}\n",
    "    emb = json.load(open(encoder_path, 'r'))\n",
    "    emb_len = len(list(emb.items())[0][1])\n",
    "    cop = json.load(open(com_path, 'r'))\n",
    "    num_keys = len(logTemp.index.unique())\n",
    "    \n",
    "    # session sample\n",
    "    inputs = []\n",
    "    for idx, row in pre_data.iterrows():\n",
    "        # seqs = row['EventSequence'][1:-1].replace('\\'', '').replace(' ','').split(',')\n",
    "        seqs = eval(row['EventSequence'])\n",
    "        len_seq = len(seqs)\n",
    "        # seqs = seqs + [-1]*(window_size + 1 - len(seqs)) # is padding?\n",
    "        inp, comp, quanp, timep, lab = [], [], [], [], []\n",
    "        for i in range(len(seqs) - window_size):\n",
    "            seq, com, tm = [], [], []\n",
    "            \n",
    "            # quan encoder\n",
    "            quan_pattern = [0] * num_keys\n",
    "            log_counter = Counter([mapping[event] for event, _, _ in seqs[i:i + window_size]])\n",
    "            for key in log_counter:\n",
    "                quan_pattern[key] = log_counter[key]\n",
    "            quanp.append(quan_pattern)\n",
    "            \n",
    "            start_time = getDateTimeFromISO8601String(seqs[i:i + window_size][0][2])\n",
    "            for event in seqs[i:i + window_size]:\n",
    "                cur_time = getDateTimeFromISO8601String(event[2])\n",
    "                seq.append([-1]*emb_len) if event[0] == -1 else seq.append(emb[event[0]])\n",
    "                com.append(-1) if event[0] == -1 else com.append(cop[event[1]])\n",
    "                tm.append(-1) if event[0] == -1 else tm.append((cur_time - start_time).seconds)\n",
    "                \n",
    "            inp.append(seq)\n",
    "            comp.append(com)\n",
    "            timep.append(tm)\n",
    "            lab.append(mapping[seqs[i + window_size][0]] if seqs[i + window_size] != -1 else -1)\n",
    "        if inp: inputs.append((inp, comp, quanp, timep, lab))\n",
    "    \n",
    "    print('Number of {}_seqs(session): {}'.format(name, len(inputs)))\n",
    "    return inputs, len(inputs), len(cop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99a30fd-b64b-45bf-8356-31f2a7efed2d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation(output, label, valid_loss, pattern='macro'):\n",
    "    accuracy = accuracy_score(label, output)\n",
    "    precision, recall, F1, _ = precision_recall_fscore_support(label, output,  average=pattern)\n",
    "    return accuracy, precision, recall, F1, np.average(valid_loss)\n",
    "\n",
    "def eval_handle(nordl, anodl, model, window_size, num_candidates, anomaly_rate = 1):\n",
    "    nor_hit = []\n",
    "    ano_hit = []\n",
    "    total_loss = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # normal valid\n",
    "        for seq, com, quan, timp, label in nordl:\n",
    "            assert len(seq) == len(label), 'seqs len not equal labels len, please check the generate'\n",
    "            seq = torch.as_tensor(seq, dtype=torch.float).to(device)\n",
    "            quan = torch.as_tensor(quan, dtype=torch.float).to(device)\n",
    "            com = torch.as_tensor(com).to(device)\n",
    "            timp = torch.as_tensor(timp, dtype=torch.float).to(device)\n",
    "            label = torch.as_tensor(label).to(device)\n",
    "            \n",
    "            output = model(seq, com, quan, timp).to(device)\n",
    "            # loss = criterion(output, label)\n",
    "            # total_loss.append(loss.item())\n",
    "            \n",
    "            indice = torch.argsort(output, 1, descending=True)[:,0:num_candidates]\n",
    "            fcnt = (torch.isin(label, indice) == False).sum().item()\n",
    "            nor_hit.append(1) if fcnt >= anomaly_rate else nor_hit.append(0)\n",
    "\n",
    "        # normal valid\n",
    "        for seq, com, quan, timp, label in anodl:\n",
    "            assert len(seq) == len(label), 'seqs len not equal labels len, please check the generate'\n",
    "            seq = torch.as_tensor(seq, dtype=torch.float).to(device)\n",
    "            quan = torch.as_tensor(quan, dtype=torch.float).to(device)\n",
    "            com = torch.as_tensor(com).to(device)\n",
    "            timp = torch.as_tensor(timp, dtype=torch.float).to(device)\n",
    "            label = torch.as_tensor(label).to(device)\n",
    "            \n",
    "            output = model(seq, com, quan, timp).to(device)\n",
    "            # loss = criterion(output, label)\n",
    "            # total_loss.append(loss.item())\n",
    "            \n",
    "            indice = torch.argsort(output, 1, descending=True)[:,0:num_candidates]\n",
    "            fcnt = (torch.isin(label, indice) == False).sum().item()\n",
    "            ano_hit.append(1) if fcnt >= anomaly_rate else ano_hit.append(0)\n",
    "            \n",
    "    nor_label = [0]*len(nor_hit)\n",
    "    ano_label = [1]*len(ano_hit)\n",
    "    \n",
    "    return evaluation(nor_hit + ano_hit, nor_label + ano_label, np.average(total_loss))\n",
    "\n",
    "def eval_handle_topK(nordl, anodl, model, window_size, num_candidates, anomaly_rate = 1):\n",
    "    nor_hit = dict()\n",
    "    ano_hit = dict()\n",
    "    total_loss = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # normal valid\n",
    "        for seq, com, quan, timp, label in nordl:\n",
    "            assert len(seq) == len(label), 'seqs len not equal labels len, please check the generate'\n",
    "            seq = torch.as_tensor(seq, dtype=torch.float).to(device)\n",
    "            quan = torch.as_tensor(quan, dtype=torch.float).to(device)\n",
    "            com = torch.as_tensor(com).to(device)\n",
    "            timp = torch.as_tensor(timp, dtype=torch.float).to(device)\n",
    "            label = torch.as_tensor(label).to(device)\n",
    "            \n",
    "            output = model(seq, com, quan, timp).to(device)\n",
    "            # loss = criterion(output, label)\n",
    "            # total_loss.append(loss.item())\n",
    "            \n",
    "            for num_can in num_candidates:\n",
    "                if num_can not in nor_hit.keys():\n",
    "                    nor_hit[num_can] = []\n",
    "                indice = torch.argsort(output, 1, descending=True)[:,0:num_can].contiguous()\n",
    "                fcnt = (torch.isin(label, indice) == False).sum().item()\n",
    "                nor_hit[num_can].append(1) if fcnt >= anomaly_rate else nor_hit[num_can].append(0)\n",
    "\n",
    "        # normal valid\n",
    "        for seq, com, quan, timp, label in anodl:\n",
    "            assert len(seq) == len(label), 'seqs len not equal labels len, please check the generate'\n",
    "            seq = torch.as_tensor(seq, dtype=torch.float).to(device)\n",
    "            quan = torch.as_tensor(quan, dtype=torch.float).to(device)\n",
    "            com = torch.as_tensor(com).to(device)\n",
    "            timp = torch.as_tensor(timp, dtype=torch.float).to(device)\n",
    "            label = torch.as_tensor(label).to(device)\n",
    "            \n",
    "            output = model(seq, com, quan, timp).to(device)\n",
    "            # loss = criterion(output, label)\n",
    "            # total_loss.append(loss.item())\n",
    "            \n",
    "            for num_can in num_candidates:\n",
    "                if num_can not in ano_hit.keys():\n",
    "                    ano_hit[num_can] = []              \n",
    "                indice = torch.argsort(output, 1, descending=True)[:,0:num_can].contiguous()\n",
    "                fcnt = (torch.isin(label, indice) == False).sum().item()\n",
    "                ano_hit[num_can].append(1) if fcnt >= anomaly_rate else ano_hit[num_can].append(0)\n",
    "            \n",
    "    nor_label = [0]*len(nor_hit[num_candidates[0]])\n",
    "    ano_label = [1]*len(ano_hit[num_candidates[0]])\n",
    "    \n",
    "    res = dict()\n",
    "    for num_can in num_candidates:\n",
    "        if num_can not in res.keys():\n",
    "            res[num_can] = []\n",
    "        res[num_can].append(evaluation(nor_hit[num_can] + ano_hit[num_can], nor_label + ano_label, np.average(total_loss)))\n",
    "    return res\n",
    "\n",
    "def eval_mulClass(nordl, anodl, model, window_size, num_candidates, anomaly_rate = 1):\n",
    "    out_list = []\n",
    "    label_list = []\n",
    "    total_loss = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "         # normal valid\n",
    "        for seq, com, quan, timp, label in nordl:\n",
    "            assert len(seq) == len(label), 'seqs len not equal labels len, please check the generate'\n",
    "            seq = torch.as_tensor(seq, dtype=torch.float).to(device)\n",
    "            quan = torch.as_tensor(quan, dtype=torch.float).to(device)\n",
    "            com = torch.as_tensor(com).to(device)\n",
    "            timp = torch.as_tensor(timp, dtype=torch.float).to(device)\n",
    "            label = torch.as_tensor(label).to(device)\n",
    "            \n",
    "            output = model(seq, com, quan, timp).to(device)\n",
    "            # loss = criterion(output, label)\n",
    "            # total_loss.append(loss.item())\n",
    "            \n",
    "            indice = torch.argsort(output, 1, descending=True)[:,0:num_candidates]\n",
    "            out_list.append(indice)\n",
    "            label_list.append(label)\n",
    "\n",
    "        # normal valid\n",
    "        for seq, com, quan, timp, label in anodl:\n",
    "            assert len(seq) == len(label), 'seqs len not equal labels len, please check the generate'\n",
    "            seq = torch.as_tensor(seq, dtype=torch.float).to(device)\n",
    "            quan = torch.as_tensor(quan, dtype=torch.float).to(device)\n",
    "            com = torch.as_tensor(com).to(device)\n",
    "            timp = torch.as_tensor(timp, dtype=torch.float).to(device)\n",
    "            label = torch.as_tensor(label).to(device)\n",
    "            \n",
    "            output = model(seq, com, quan, timp).to(device)\n",
    "            # loss = criterion(output, label)\n",
    "            # total_loss.append(loss.item())\n",
    "            \n",
    "            indice = torch.argsort(output, 1, descending=True)[:,0:num_candidates]\n",
    "            out_list.append(indice)\n",
    "            label_list.append(label)\n",
    "        \n",
    "    return evaluation(torch.cat(out_list).cpu(), torch.cat(label_list).cpu(), np.average(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "593b33c2-712c-4582-82e4-fb485404e672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 16\n",
    "num_epochs = 2\n",
    "# 6,7,8,9,10,11,12,13,14\n",
    "window_sizes = [9]\n",
    "# ft_hid_size, lstm_hid_size, mlp_hid_size, gcn_hid_size, out_hid_size\n",
    "hidden_size = [64, 64, 64, 64, 64]\n",
    "alpha = 0.8\n",
    "pattern = 1\n",
    "\n",
    "num_layers = 2\n",
    "drop = 0.1\n",
    "num_candidates = [1]\n",
    "anomaly_rate = 1\n",
    "patience = 20\n",
    "\n",
    "# data path\n",
    "name = '..'\n",
    "used_name = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c2c2e2-e76b-46dc-8c18-d6355118683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_size in window_sizes:\n",
    "    train_path, val_normal_path, val_anomaly_path, temp_path, emb_path, com_path, test_normal_path, test_anomaly_path = getPath(name, used_name, 'sen')\n",
    "    train_dataset, attr_num, class_num, com_num = generate_train('HDFS_train', train_path, temp_path, emb_path, com_path, window_size)\n",
    "    dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=False)\n",
    "\n",
    "    label_normal, normal_len, com_num = generate_pre('HDFS_val_normal', val_normal_path, temp_path, emb_path, com_path, window_size)\n",
    "    label_anomaly, anomal_len, com_num = generate_pre('HDFS_val_anomaly', val_anomaly_path, temp_path, emb_path, com_path, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06d9ce4-03a1-43b8-b047-a7e8014e24b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(attr_num, com_num, hidden_size, alpha, pattern, \\\n",
    "                              num_layers, class_num, drop, True).to(device)\n",
    "# 统计模型参数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61440e4-b8b4-417a-9b53-b976e632e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLOPs\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
    "\n",
    "print(parameter_count_table(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7652793-8a15-482f-8ba9-e8edc92af4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_size in window_sizes:\n",
    "    train_path, val_normal_path, val_anomaly_path, temp_path, emb_path, com_path, test_normal_path, test_anomaly_path = getPath(name, used_name, 'sen')\n",
    "    train_dataset, attr_num, class_num, com_num = generate_train('HDFS_train', train_path, temp_path, emb_path, com_path, window_size)\n",
    "    dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=False)\n",
    "\n",
    "    label_normal, normal_len, com_num = generate_pre('HDFS_val_normal', val_normal_path, temp_path, emb_path, com_path, window_size)\n",
    "    label_anomaly, anomal_len, com_num = generate_pre('HDFS_val_anomaly', val_anomaly_path, temp_path, emb_path, com_path, window_size)\n",
    "    print('data loaded')\n",
    "    modelLs = []\n",
    "\n",
    "    modelLs.append(Model(attr_num, com_num, hidden_size, alpha, pattern, \\\n",
    "                              num_layers, class_num, drop, True).to(device))\n",
    "    # modelLs.append(Model_wo_ic(attr_num, com_num, hidden_size, alpha, pattern, \\\n",
    "    #                           num_layers, class_num, drop, True).to(device))\n",
    "    # modelLs.append(Model_wo_LSTM(attr_num, com_num, hidden_size, alpha, pattern, \\\n",
    "    #                           num_layers, class_num, drop, True).to(device))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for model in modelLs:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    \n",
    "    best_x, best_epoch = 0, 0\n",
    "\n",
    "    label = None\n",
    "    indice = None\n",
    "    for epoch in range(num_epochs):  # Loop over the dataset multiple times\n",
    "        train_loss = []\n",
    "        model.train()\n",
    "        for step, (seq, com, quan, timp, label) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            # feature loaded\n",
    "            seq = seq.clone().detach().to(device)\n",
    "            com = com.clone().detach().to(device)\n",
    "            quan = quan.clone().detach().to(device)\n",
    "            timp = timp.clone().detach().to(device)\n",
    "\n",
    "            output = model(seq, com, quan, timp).to(device)\n",
    "            loss = criterion(output, label.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "        print('Epoch [{}/{}], train_loss: {:.4f}'.format(epoch + 1, num_epochs, np.average(train_loss)))\n",
    "        train_loss = []\n",
    "        # val model\n",
    "        # accuracy, precision, recall, F1, val_loss = eval_handle(label_normal, label_anomaly, model, window_size, num_candidates[0], anomaly_rate)\n",
    "        # accuracy, precision, recall, F1, val_loss = eval_mulClass(label_normal, label_anomaly, model, window_size, num_candidates, anomaly_rate)\n",
    "        # print(\"Accuracy: {0:.3f}, Precision: {1:.3f}, Recall: {2:.3f}, F1-score: {3:.3f}\".format(accuracy, precision, recall, F1))\n",
    "        res = eval_handle_topK(label_normal, label_anomaly, model, window_size, num_candidates, anomaly_rate)\n",
    "        for item in res.items():\n",
    "            accuracy, precision, recall, F1, _ = item[1][0]\n",
    "            print(\"TopK={0} | Accuracy: {1:.3f}, Precision: {2:.3f}, Recall: {3:.3f}, F1-score: {4:.3f}\".format(item[0], accuracy, precision, recall, F1))\n",
    "            if best_x <= F1:\n",
    "                best_x = F1\n",
    "                best_epoch = epoch\n",
    "                # 保存模型\n",
    "                state = {'model':model.state_dict(), 'optimizer':optimizer.state_dict(), 'epoch': best_epoch}\n",
    "        # if patience != 0:\n",
    "        #     early_stopping(val_loss, model)\n",
    "        #     if early_stopping.early_stop:\n",
    "        #         print(\"Early stopping\")\n",
    "        #         break\n",
    "\n",
    "    print(\"best epoch:{} / best F1:{:.3f}\".format(best_epoch + 1, best_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c292b-a171-4992-8e5b-3892899ca284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "model.load_state_dict(state['model'])\n",
    "model.eval()\n",
    "\n",
    "label_normal, normal_len, _ = generate_pre('HDFS_test_normal', test_normal_path, temp_path, emb_path, com_path, window_size)\n",
    "label_anomaly, anomal_len, _ = generate_pre('HDFS_test_anomaly', test_anomaly_path, temp_path, emb_path, com_path, window_size)\n",
    "\n",
    "res = eval_handle_topK(label_normal, label_anomaly, model, window_size, num_candidates, anomaly_rate)\n",
    "\n",
    "for item in res.items():\n",
    "    accuracy, precision, recall, F1, _ = item[1][0]\n",
    "    print(\"TopK={0} | Accuracy: {1:.3f}, Precision: {2:.3f}, Recall: {3:.3f}, F1-score: {4:.3f}\".format(item[0], accuracy, precision, recall, F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9894b3-a009-4cce-8c89-52c7bcb012e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "model_dir = 'model/CSCLog/'\n",
    "name = 'CSCLog'\n",
    "torch.save(state, model_dir + '/' + name + '.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
